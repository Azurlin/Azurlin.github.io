{"pages":[],"posts":[{"title":"Hello World 你好","text":"测试","link":"/2020/06/25/hello-world/"},{"title":"HDFS","text":"一、概述 HDFS（Hadoop Distributed File System）是hadoop提供的一套用于进行分布式文件存储的系统。 HDFS是doug仿照Google的GFS（Google File System）来实现的。 云主机启动hadoop 通过本地浏览器访问IP:50070监控hadoop。 二、技术细节 基本概述 随着数据量的不断增大，单机存储方式已经不能够适应生产环境，所以我们需要引入分布式存储。 HDFS是一个典型的MS结构：主节点是NameNode，从节点是DataNode。 在HDFS中存储数据时，会对数据进行切分，切成不同的数据块Block。 HDFS会对存入其中的Block进行备份，这个备份称之为副本。HDFS中默认的副本策略是3，既需要复制2次加上原来的副本构成3个副本。 HDFS提供了一套类似于linux的文件系统，即仿照Linux，允许用户产生不同的目录，同时为不同的路径设计权限。根路径是/。 Block 数据块 Block是HDFS中的基本存储单位，即所有的数据都是以block形存储的。 Block默认大小不超过128M(可以通过属性 dfsblocksize调节–hdsf/site.xml 单位是字节默认是)。 如果上传的文件不足一个Block大小，那么这个文件是多大对应的Block就是多大。例如一个文件15M那么对应的Block就是15M。 每一个Block都会分配一个编号BlockID。 HDFS会记录每一个Block上传的时间，但是并不是直接记录时间，而是给时间戳一个编号Generation Stamp。 Block的意义a. 能够存储超大文件 b. 能够迅速的备份 一个DataNode可能会存储很多个Block。 NameNode 主节点 NameNode是HDFS中的主节点。 作用：管理DataNode，存储元数据。 元数据是对数据描述的数据，元数据中不包含具体的数据内容 -账本 元数据主要包含1) 文件的上传路径 2) 上传的用户名以及对应的权限 3) 文件的大小 4) Block的大小 5) 文件和BlockID的映射关系 6) BlockID和DataNode的映射关系 7) 文件的副本数量 NameNode会将元数据维系在磁盘以及内存中1) 在磁盘中是为了崩溃恢复 2) 在内存中是为了读写快 元数据的存储位置有属性hadoop.tmp.dir来决定，如果不配置则默认放在/tmp下，所以需要更改路径。 与元数据相关的文件○ edits：操作文件，用于记录HDFS的写操作。 ○ fsimage：元数据（映像）文件，用于记录HDFS的元数据。 当NameNode收到写操作的时候，先将写操作记录到edits_inprogress文件中，如果记录成功，则修改内存中的元数据，如果修改成功，则给客户端返回一个ack信号表示成功。注意，此时fsimage文件中的元数据并没有发生改变。 当edits_inprogress文件达到指定条件的时候，产生一个新的edits_inprogress用来记录新的写操作，同时原来的edits_inprogress会滚动改名为edits，新生成的edits文件会将其中写操作一一取出重新执行来更新fsimage中的元数据。 edits_inprogress滚动条件○ 空间：edits_inprogress文件达到指定大小(默认是64M，通过属性fs.checkpoint.size来调节，配置在core-site.xml，单位是字节)之后，会滚动生成edits。○ 时间：当距离上一次滚动的间隔时间达到指定大小（默认是1h，通过属性fs.checkpoint.period来调节，配置在core-site.xml，单位是秒）的时候，eidts——inprogress也会滚动。○ 重启：当NameNode重启的时候，自动触发edits_inprogress文件的滚动○ 强制滚动：通过hadoop dfadmin -rollEdits来进行强制滚动。 NameNode通过心跳机制来管理DataNode。DataNode定时给NameNode发送心跳信息。 心跳信息通过RPC方式发送。 心跳间隔时间默认为3s，通过属性dfs.heartbeat.interval来调节，单位是秒。 如果NameNode超过10min没有收到DataNode的心跳，则认为这个DataNode已经lost（丢失），那么就会将这个DataNode上的数据备份到其他节点上保证副本数量。 心跳信息○ clusterid：集群编号。在NameNode被格式化（hadoop namenode -format）的时候，自动计算产生一个clusterid。NameNode会将clusterid发送给每一个DataNode，DataNode收到clusterid之后会存储在本地。之后DataNode和NameNode的每一次通信都需要携带clusterid。NameNode在收到DataNode的信号之后会先校验clusterid是否一致，如果不一致则直接抛弃。如果一致，NameNode才会处理DataNode的请求。DataNode只接受一次clusterid。NameNode每次格式化都会产生一个新的clusterid，如果NameNode被格式化多次，就会发现NameNode联系不上DataNode，此时通过jps命令查看，发现要么缺少NameNode要么缺少DataNode。○ DataNode的节点状态：预服役、服役、预退役。○ Block的存储信息 安全模式（safe mode）1) 当NameNode产生重启的时候，首先会触发edits_inprogress文件的滚动，产生edits文件之后会更新fsimage文件中的元数据。2) 当fsimage文件中的元数据更新完成之后，NameNode会将fsimage中的元数据加载到内存中。3) 元数据加载完成之后，NameNode等待DataNode的心跳。4) 如果NameNode没有收到心跳，则会试图备份这个DataNode上的数据到其他的DataNode上。5) NameNode在收到DataNode的心跳之后会进行校验。校验Block信息（Block大小、数量等）。6) 如果校验失败则NameNode会试图恢复这个数据；恢复完成之后会再次校验。7) 如果所有的DataNode都校验成功，则会自动退出安全模式。 在安全模式中，HDFS不对外提供写服务。 NameNode在重启时会自动进入安全模式。如果在进行操作的时候发现HDFS处在安全模式中，那么需要等待一会儿，等他自动退出安全模式。如果在合理的时间内，HDFS没有退出安全模式，那么说明数据产生了无法挽回的丢失。此时只能强制退出安全模式（hadoop dfsadmin -safemode leave）。 正因为安全模式和副本放置策略的存在，所以在伪分布式中副本数量必须为1 - 副本数量不能超过节点数量。 NameNode在HDFS中处于核心地位，但是在Hadoop1.0，NameNode只能由1个，在Hadoop2.0中通过舍弃SecondaryNameNode可以允许存在2个NameNode，在Hadoop3.0中，NameNode的个数不再限制。 副本放置策略 在HDFS中，默认采用多副本机制，默认副本数量为3，通过dfs.replication属性来进行设置，配置在hdfs-site.xml文件中。 放置策略 a. 第一个副本1) 如果是集群内部上传，则谁上传第一个副本就放在谁身上。 2) 如果是集群外部上传，则谁相对空闲就放到谁身上。 b. 第二个副本1) Hadoop2.7之前：第二个副本是放在和第一个副本不同机架的节点上 2) Hadoop2.7开始：第二个副本是放在和第一个副本相同的机架的节点上 c. 第三个副本1) Hadoop2.7之前：第三个副本是放在和第二个副本相同机架的节点上 2) Hadoop2.7开始：第三个副本是放在和第二个副本不同机架的节点上 d. 更多副本：放置在相对空闲的DataNode上。 机架感知策略 默认情况下，Hadoop的机架感知策略没有被启用，所以HDFS在存放数据的时候都是选择相对空闲的节点来存储。 通过脚本文件来指定机架感知。脚本文件可以是Shell/Python语言编写。 通过一个Map来指定机架，其中将主机的主机名或者IP作为Map的键，然后将机架名作为值。只要值一样，就意味着这些键对应的主机就在一个机架上 - 这个Map称之为逻辑机架。 理论上可以将不同的物理机架上的节点配置在相同的逻辑机架上（只要保持值相同即可），但是这样不利于管理，所以实际过程中，一般是将统一个物理机架上的节点配置在同一个逻辑机架上。 SecondaryNameNode SecondaryNameNode不是NameNode的备份，仅仅是辅助NameNode完成edits文件的滚动和fsimage文件的更新。 如果存在SecondaryNameNode，那么edits文件的滚动和fsimage文件的更新是发生在SecondaryNameNode上。如果不存在，则上述过程发生在NameNode。 到目前为止，HDFS2.0只支持2种结构。a. 1个NameNode+1个SecondaryNameNode+多个DataNode。 b. 2个NameNode（构成备份）+多个DataNode。 考虑到NameNode的核心地位，所以需要考虑NameNode的备份问题，所以一般采用的是第二种结构：2个NameNode(Active状态+Standby备份状态)+多个DataNode。 DataNode 作用：存储数据，数据是以Block形式存在。 DataNode将数据存储在磁盘上（数据多），在磁盘上的存储位置由属性hadoop.tmp.dir来决定。 DataNode会为每一个Block生成一个.meta文件，.meta实际上是对Block的校验（.meta中存储了一个校验值，这个校验值是根据Block大小、生成时间、存储内容等信息进行非对称加密计算出来的一个整数）。DataNode给NameNode发送心跳的时候是包含这个加密值的，如果更改了Block内容，那么.meta文件中的内容也会重新计算。 DataNode通过心跳机制来向NameNode发送信息。 基本命令 hadoop fs -put /home/a.txt /b.txt 将/home/a.txt上传到HDFS的根目录下并且重命名为b.txt hadoop fs -mkdir /log 在HDFS的/下创建子目录log hadoop fs -get /a.txt /home 将HDFS的/a.txt下载到本地的/home目录下 hadoop fs -mv /a.txt /b.txt 重命名 hadoop fs -mv /a.txt /log/a.txt 剪切 hadoop fs -cp /a.txt /c.txt 复制 hadoop fs -chmod 777 /a.txt 修改权限 hadoop fs -ls / 查看/下的子文件和子目录 hadoop fs -lsr / 递归查看 hadoop fs -rm /a.txt 删除文件 hadoop fs -rmdir /test 删除目录，要求目录为空 hadoop fs -rmr /log 递归删除目录 回收站机制 在HDFS中，回收站机制默认是不开启的（即默认值为0），所以一个文件如果被删除，会立即从HDFS上移除，这个操作不可撤销。 回收站机制需要core-site.xml中配置。","link":"/2020/06/25/HDFS/"}],"tags":[{"name":"测试","slug":"测试","link":"/tags/%E6%B5%8B%E8%AF%95/"},{"name":"大数据","slug":"大数据","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"categories":[{"name":"分类测试","slug":"分类测试","link":"/categories/%E5%88%86%E7%B1%BB%E6%B5%8B%E8%AF%95/"}]}