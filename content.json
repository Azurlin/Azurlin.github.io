{"pages":[{"title":"","text":"TheSun 汪汪汪~汪汪~汪汪汪","link":"/link/index.html"},{"title":"","text":"关于Az 凡是金子未必会发光。 知识就是力量。 神秘内容 这个人... ● 是个阿宅。 ● 喜欢猫咪。想养一只虎斑暹罗。 ● 是一个随性的游戏玩家，最爱的游戏是血源和旷野之息。 ● 喜欢星际牛仔和混沌武士。 ● 喜欢老歌曲,喜欢citypop,Jazz Hiphop和摇滚乐。 ● 喜欢山岡晃、西原健一郎和Nujabes。 ● 想成为游戏制作人。 ● 以及更多... 与我交流 QQ:1360520223 WeChat：FuGatto email:azurlin@outlook.com 神秘代码 Nintendo:SW-5292-6396-8412 PSN:azazlin Steam:Azurlin","link":"/about/index.html"}],"posts":[{"title":"MapReduce之Shuffle","text":"Map端的Shuffle map方法在产生数据之后，并不是直接把数据发送个ReduceTask,而是先将数据临时存储到缓冲区中。 在缓冲区中会进行分区（partition）、排序（sort），如果指定了Combiner还会进行combine。 每一个MapTask都会自带一个缓冲区。缓冲区维系在内存中，默认大小是100M。 当缓冲区使用达到阈值(默认0.8)的时候，会产生溢写（spill）,将数据溢写到磁盘中并生成溢写文件。 溢写之后，新来的数据依然是写到缓冲区中，如果再次达到阈值会产生溢写，每一次溢写都会生成新的溢写文件。单个溢写文件是分区并且有序的。 当MapTask处理完所有数据后会将所有的溢写文件合并(merge 不改变数据量)到一个文件中，生成结果文件(final out)。如果缓冲区存在数据，则会一起merge到final out中。无论如何都会产生final out。 在merge过程中会对数据再次进行分区排序，最后的final out一定是分区且有序的。 注意: 缓冲区本质上是一个环形字节数组，条形容器如果想要重复使用是需要重复寻址的，而环状则避免了重复寻址的过程。 阈值的作用是为了减少阻塞，当使用量达到阈值时，便开始从头部溢写，这样即便后来的数据在环形容器中覆盖了头部也不会丢失数据。 溢写过程不一定产生。要看map处理完后是否达到阈值。 溢写次数与原始数据量大小无关数据量大小跟溢写次数没有关系，map处理完后达到阈值才会产生溢写。 溢写文件的大小要考虑序列化的过程。 从内存到磁盘有一个序列化的过程，这个过程发生在触发溢写之后，序列化过程中可能丢弃一些不需要的数据或者添加一些数据，最终生成的溢写文件可能小于阈值也可能大于阈值。 两次排序：整个过程会发生两次排序，这两次排序是不同的。第一次发生在缓冲区中，数据是从完全杂乱的到有序的状态这个过程采用的是快速排序，第二次各个有序的部分的排序，是从局部有序到整体有序，这个过程采用的是归并排序。 Reduce端的Shuffle 当达到启动阈值（默认0.05，当5%的MapTask结束）的时候，ReduceTask就会启动抓取MapTask的数据。 ReduceTask启动fetch线程（每个ReduceTack默认最多启动五个fetch线程）通过get请求（携带分区信号）的方式来抓取数据，抓取数据时只抓取当前要处理的分区的数据。 ReduceTask会将抓取来的每一段数据临时存储到本地磁盘上，抓取完成之后，会通过merge操作将这些临时文件合并成一个总的文件。在merge的过程中，会再次对数据排序。这次排序采用的是归并排序。 merge操作完成后，就将这个文件中相同的键对应的值分到一组去，形成一个伪迭代器（reduce中的迭代是在读取文件的时候发生的，控制指针从文件逐行读取数据，因为数据是经过排序的相同的key依次排列下来，通过比较相同的key分到一组遇到不同则开启新一轮的reduce。只有指针没有容器，因此Reduce中的迭代器只能使用一次，当指针移动之后便不能再次重复使用了–这么设计的原因是考虑到数据量大的情况，是迭代设计模式的应用）。这个过程被称为分组。 注意问题： 设置启动阈值的目的是为了提高执行效率节省时间。 merge factor（合并因子）默认是10，即每十个小文件合并一次（如果文件个数超过merge因子，那么最终需要整理成merge因子大小再进行合并。），最终合并成一个总的文件。 Shuffle的优化与磁盘的交互会大大降低效率，为了提高性能要通过各种方案减小与磁盘的交互。 增大缓冲区，实际开发中缓冲区一般是250M~400M。 增大溢写阈值，可能导致阻塞的风险增加（不建议）。 增加Combine过程。通过合并减少数据体量。 考虑将final out压缩之后再传输。但是解压和压缩需要耗费时间和CPU，这种方案是在网络资源和压缩时间的取舍。 调节ReduceTask的启动阈值（不建议）。文件大小数量不确定需要根据实际情况而定。 适当增加fetch线程的数量。一般在5000~10000之间 可以考虑调大merge因子（不建议）。","link":"/2020/07/01/BigData/MapReduce/MapReduce%E4%B9%8BShuffle/"},{"title":"HDFS","text":"概述 HDFS（Hadoop Distributed File System）是hadoop提供的一套用于进行分布式文件存储的系统。 HDFS是doug仿照Google的GFS（Google File System）来实现的。 云主机启动hadoop 通过本地浏览器访问IP:50070监控hadoop。 技术细节基本概述 随着数据量的不断增大，单机存储方式已经不能够适应生产环境，所以我们需要引入分布式存储。 HDFS是一个典型的MS结构：主节点是NameNode，从节点是DataNode。 在HDFS中存储数据时，会对数据进行切分，切成不同的数据块Block。 HDFS会对存入其中的Block进行备份，这个备份称之为副本。HDFS中默认的副本策略是3，既需要复制2次加上原来的副本构成3个副本。 HDFS提供了一套类似于linux的文件系统，即仿照Linux，允许用户产生不同的目录，同时为不同的路径设计权限。根路径是/。 Block 数据块 Block是HDFS中的基本存储单位，即所有的数据都是以block形存储的。 Block默认大小不超过128M(可以通过属性 dfsblocksize调节–hdsf/site.xml 单位是字节默认是)。 如果上传的文件不足一个Block大小，那么这个文件是多大对应的Block就是多大。例如一个文件15M那么对应的Block就是15M。 每一个Block都会分配一个编号BlockID。 HDFS会记录每一个Block上传的时间，但是并不是直接记录时间，而是给时间戳一个编号Generation Stamp。 Block的意义a. 能够存储超大文件 b. 能够迅速的备份 一个DataNode可能会存储很多个Block。 NameNode 主节点 NameNode是HDFS中的主节点。 作用：管理DataNode，存储元数据。 元数据是对数据描述的数据，元数据中不包含具体的数据内容 -账本 元数据主要包含1) 文件的上传路径 2) 上传的用户名以及对应的权限 3) 文件的大小 4) Block的大小 5) 文件和BlockID的映射关系 6) BlockID和DataNode的映射关系 7) 文件的副本数量 NameNode会将元数据维系在磁盘以及内存中1) 在磁盘中是为了崩溃恢复 2) 在内存中是为了读写快 元数据的存储位置有属性hadoop.tmp.dir来决定，如果不配置则默认放在/tmp下，所以需要更改路径。 与元数据相关的文件○ edits：操作文件，用于记录HDFS的写操作。 ○ fsimage：元数据（映像）文件，用于记录HDFS的元数据。 当NameNode收到写操作的时候，先将写操作记录到edits_inprogress文件中，如果记录成功，则修改内存中的元数据，如果修改成功，则给客户端返回一个ack信号表示成功。注意，此时fsimage文件中的元数据并没有发生改变。 当edits_inprogress文件达到指定条件的时候，产生一个新的edits_inprogress用来记录新的写操作，同时原来的edits_inprogress会滚动改名为edits，新生成的edits文件会将其中写操作一一取出重新执行来更新fsimage中的元数据。 edits_inprogress滚动条件○ 空间：edits_inprogress文件达到指定大小(默认是64M，通过属性fs.checkpoint.size来调节，配置在core-site.xml，单位是字节)之后，会滚动生成edits。○ 时间：当距离上一次滚动的间隔时间达到指定大小（默认是1h，通过属性fs.checkpoint.period来调节，配置在core-site.xml，单位是秒）的时候，eidts——inprogress也会滚动。○ 重启：当NameNode重启的时候，自动触发edits_inprogress文件的滚动○ 强制滚动：通过hadoop dfadmin -rollEdits来进行强制滚动。 NameNode通过心跳机制来管理DataNode。DataNode定时给NameNode发送心跳信息。 心跳信息通过RPC方式发送。 心跳间隔时间默认为3s，通过属性dfs.heartbeat.interval来调节，单位是秒。 如果NameNode超过10min没有收到DataNode的心跳，则认为这个DataNode已经lost（丢失），那么就会将这个DataNode上的数据备份到其他节点上保证副本数量。 心跳信息○ clusterid：集群编号。在NameNode被格式化（hadoop namenode -format）的时候，自动计算产生一个clusterid。NameNode会将clusterid发送给每一个DataNode，DataNode收到clusterid之后会存储在本地。之后DataNode和NameNode的每一次通信都需要携带clusterid。NameNode在收到DataNode的信号之后会先校验clusterid是否一致，如果不一致则直接抛弃。如果一致，NameNode才会处理DataNode的请求。DataNode只接受一次clusterid。NameNode每次格式化都会产生一个新的clusterid，如果NameNode被格式化多次，就会发现NameNode联系不上DataNode，此时通过jps命令查看，发现要么缺少NameNode要么缺少DataNode。○ DataNode的节点状态：预服役、服役、预退役。○ Block的存储信息 安全模式（safe mode）1) 当NameNode产生重启的时候，首先会触发edits_inprogress文件的滚动，产生edits文件之后会更新fsimage文件中的元数据。2) 当fsimage文件中的元数据更新完成之后，NameNode会将fsimage中的元数据加载到内存中。3) 元数据加载完成之后，NameNode等待DataNode的心跳。4) 如果NameNode没有收到心跳，则会试图备份这个DataNode上的数据到其他的DataNode上。5) NameNode在收到DataNode的心跳之后会进行校验。校验Block信息（Block大小、数量等）。6) 如果校验失败则NameNode会试图恢复这个数据；恢复完成之后会再次校验。7) 如果所有的DataNode都校验成功，则会自动退出安全模式。 在安全模式中，HDFS不对外提供写服务。 NameNode在重启时会自动进入安全模式。如果在进行操作的时候发现HDFS处在安全模式中，那么需要等待一会儿，等他自动退出安全模式。如果在合理的时间内，HDFS没有退出安全模式，那么说明数据产生了无法挽回的丢失。此时只能强制退出安全模式（hadoop dfsadmin -safemode leave）。 正因为安全模式和副本放置策略的存在，所以在伪分布式中副本数量必须为1 - 副本数量不能超过节点数量。 NameNode在HDFS中处于核心地位，但是在Hadoop1.0，NameNode只能由1个，在Hadoop2.0中通过舍弃SecondaryNameNode可以允许存在2个NameNode，在Hadoop3.0中，NameNode的个数不再限制。 副本放置策略 在HDFS中，默认采用多副本机制，默认副本数量为3，通过dfs.replication属性来进行设置，配置在hdfs-site.xml文件中。 放置策略 a. 第一个副本1) 如果是集群内部上传，则谁上传第一个副本就放在谁身上。 2) 如果是集群外部上传，则谁相对空闲就放到谁身上。 b. 第二个副本1) Hadoop2.7之前：第二个副本是放在和第一个副本不同机架的节点上 2) Hadoop2.7开始：第二个副本是放在和第一个副本相同的机架的节点上 c. 第三个副本1) Hadoop2.7之前：第三个副本是放在和第二个副本相同机架的节点上 2) Hadoop2.7开始：第三个副本是放在和第二个副本不同机架的节点上 d. 更多副本：放置在相对空闲的DataNode上。 机架感知策略 默认情况下，Hadoop的机架感知策略没有被启用，所以HDFS在存放数据的时候都是选择相对空闲的节点来存储。 通过脚本文件来指定机架感知。脚本文件可以是Shell/Python语言编写。 通过一个Map来指定机架，其中将主机的主机名或者IP作为Map的键，然后将机架名作为值。只要值一样，就意味着这些键对应的主机就在一个机架上 - 这个Map称之为逻辑机架。 理论上可以将不同的物理机架上的节点配置在相同的逻辑机架上（只要保持值相同即可），但是这样不利于管理，所以实际过程中，一般是将统一个物理机架上的节点配置在同一个逻辑机架上。 SecondaryNameNode SecondaryNameNode不是NameNode的备份，仅仅是辅助NameNode完成edits文件的滚动和fsimage文件的更新。 如果存在SecondaryNameNode，那么edits文件的滚动和fsimage文件的更新是发生在SecondaryNameNode上。如果不存在，则上述过程发生在NameNode。 到目前为止，HDFS2.0只支持2种结构。a. 1个NameNode+1个SecondaryNameNode+多个DataNode。 b. 2个NameNode（构成备份）+多个DataNode。 考虑到NameNode的核心地位，所以需要考虑NameNode的备份问题，所以一般采用的是第二种结构：2个NameNode(Active状态+Standby备份状态)+多个DataNode。 DataNode 作用：存储数据，数据是以Block形式存在。 DataNode将数据存储在磁盘上（数据多），在磁盘上的存储位置由属性hadoop.tmp.dir来决定。 DataNode会为每一个Block生成一个.meta文件，.meta实际上是对Block的校验（.meta中存储了一个校验值，这个校验值是根据Block大小、生成时间、存储内容等信息进行非对称加密计算出来的一个整数）。DataNode给NameNode发送心跳的时候是包含这个加密值的，如果更改了Block内容，那么.meta文件中的内容也会重新计算。 DataNode通过心跳机制来向NameNode发送信息。 基本命令 命令 解释 hadoop fs -put /home/a.txt /b.txt 将/home/a.txt上传到HDFS的根目录下并且重命名为b.txt hadoop fs -mkdir /log 在HDFS的/下创建子目录log hadoop fs -get /a.txt /home 将HDFS的/a.txt下载到本地的/home目录下 hadoop fs -mv /a.txt /b.txt 重命名 hadoop fs -mv /a.txt /log/a.txt 剪切 hadoop fs -cp /a.txt /c.txt 复制 hadoop fs -chmod 777 /a.txt 修改权限 hadoop fs -ls / 查看/下的子文件和子目录 hadoop fs -lsr / 递归查看 hadoop fs -rm /a.txt 删除文件 hadoop fs -rmdir /test 删除目录，要求目录为空 hadoop fs -rmr /log 递归删除目录 回收站机制 在HDFS中，回收站机制默认是不开启的（即默认值为0），所以一个文件如果被删除，会立即从HDFS上移除，这个操作不可撤销。 回收站机制需要core-site.xml中配置。 DFS目录 DFS目录的位置实际上由hadoop.tmp.dir来指定，本质上是HDFS的数据目录 DFS目录是在NameNode被格式化(hadoop namenode -format)的时候产生的 DFS的子目录 - 实际过程中，三个子目录应该是出现在不同的节点上 data：DataNode的数据目录 name：NameNode的数据目录 namesecondary：SecondaryNameNode的数据目录 当对应进程开启的时候，HDFS对应的子目录下回出现in_use.lock。 in_use.lock标记已经开启进程，防止重复开启。 在HDFS第一次启动的时候，启动之后1min，edits_inprogress会自动产生一次滚动，之后都是按照默认时间间隔(1H)来滚动。 在HDFS中，会将每一次的写操作看作是一个事务，分配一个事务id，称之为txid。 在HDFS中，将开始记录日志也看作是一个写操作也分配了一个事务id 任意一个edits文件的开头都是OP_START_LOG_SEGMENT，结尾都是OP_END_LOG_SEGMENT。这两步虽然当作写操作给分配了事务id，但是并没有产生元数据。 上传文件，NameNode会将这个请求拆分 OP_ADD：生成同名文件.COPYING OP_ALLOCATE_BLOCK_ID：分配BlockID OP_SET_GENSTAMP_V2：分配时间戳编号 OP_ADD_BLOCK：将Block的文件名对应 OP_CLOSE：关流 OP_RENAME_OLD：重命名 在HDFS中，文件一旦上传完毕就不能修改 edits的转化命令：hdfs oev -i edits_xxx -o a.xml fsimage的转化命令：hdfs oiv -i fsimage_xxx -o b.xml -p XML 每一个fsimage文件都会对应一个md5文件，这个md5文件是对fsimage文件来进行校验的 VERSION文件中的重要属性 clusterID：用于进行校验的 storageType：用于标记节点类型的 blockpoolID：块池编号。主要是用于联邦HDFS中 工作流程读/下载流程 客户端发起RPC请求到NameNode。 NameNode在收到请求之后，会检查要读取的文件是否存在；如果不存在，则直接报错；如果存在，则会给客户端来返回一个信号表示允许读取。 客户端在收到信号之后，会再次给NameNode发送请求，请求获取第一个Block的存储位置。 NameNode在收到请求之后，会查询元数据，然后将这个Block的存储位置(默认3个)放到一个队列中返回给客户端。 客户端在收到队列之后，将地址从队列中全部取出，从这些地址中选取一个较近的节点来读取这个Block的数据同时读取对应的meta文件，读取完成之后会对这个Block进行checksum校验(实际上就是利用meta文件校验Block)，检查校验结果，如果校验失败则客户端会通知NameNode，客户端会从剩余的地址中重选选择一个重新读取。 如果校验成功，则客户端会给NameNode发送请求，请求获取下一个Block的存储位置，重复3.4.5三个步骤。 直到读取完所有的Block，客户端会给NameNode发送结束信号。NameNode收到信号之后会关闭文件(关流)。 写/上传流程 客户端发起RPC请求到NameNode。 NameNode在收到请求之后，会进行校验： 校验是否有写入权限 校验路径下是否有同名文件 如果校验失败则直接报错；如果校验成功，则NameNode会记录元数据，然后会给客户端返回一个信号表示允许上传。 客户端收到信号之后，会再次发送请求到NameNode，请求获取第一个Block的存储位置。 NameNode收到请求之后，会根据副本策略等待DataNode的心跳，然后给这个Block来分配DataNode，将DataNode的地址(默认3个)放到队列中返回给客户端客户端收到队列之后，将地址从队列中取出，从这些地址中选择较近(拓扑距离)的节点将这个Block的第一个副本写入。当第一个副本写完之后，第一个副本所在的节点会通过管道(pipeline，本质上就是NIO中的Channel)将第二个副本写到对应的节点上，第二个副本写完之后，第二个副本所在的节点通过管道将第三个副本写入对应的节点上。第三个副本写完之后，第三个副本所在的节点会给第二个副本所在的节点返回一个ack信号表示写入成功；第二个副本收到ack之后会给第一个副本所在的节点返回一个ack信号；第一个副本所在的节点收到ack之后会再给客户端返回一个ack。 客户端在收到ack之后表示当前Block的所有副本都已经写完，那么客户端就会给NameNode发送请求来获取下一个Block的地址，重复4.5.6三步。 当所有的Block都写完之后，客户端就会给NameNode发送信号表示文件写完，NameNode在收到信号之后会关闭文件(实际上就是关流)。 删除流程 客户端发起RPC请求到NameNode NameNode收到请求之后会将这个操作记录到edits中，记录完成之后会修改内存中的元数据，修改完成之后会给客户端返回一个ack信号表示删除成功。此时只是修改了元数据，真正的数据依然存储在DataNode上。 NameNode会等待DataNode的心跳，收到心跳之后会校验存储信息，如果发现不一致，则会在心跳响应中要求删除对应的Block。 DataNode在收到心跳响应之后，会删除对应的Block，此时数据才真正的从HDFS上移除。","link":"/2020/06/25/BigData/Hadoop/HDFS/"},{"title":"MapReduce在Windows下的兼容问题","text":"Hadoop对windows的兼容性并不强，所以我们在使用前需要进行一些配置。 配置环境变量。新建系统变量HADOOP_USER_NAME指定变量值为root。新建HADOOP_HOME变量指定路径hadoop根目录。修改Path,新加%HADOOP_HOME%\\bin。 启动winutils.exe报错，将msvcr120.dll文件复制到c:\\Windows\\System32目录下。 出现null\\bin\\winutils。先检查环境 变量是否正确。如果环境变量正确，那么在Driver中添加System.setPeoperty(\"hadoop.home.dir\",\"Hadoop安装路径\")。 出现NativeIO$Windows。检查环境变量，没有问题将bin目录下的hadoop.dll复制到C:\\Windows\\System32目录下，然后重启IDEA，再重新运行代码。如果以上方案不可行就将NativeIO.java文件复制到对应工程。 NativeIo.java >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696package org.apache.hadoop.io.nativeio;import java.io.File;import java.io.FileDescriptor;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.io.RandomAccessFile;import java.lang.reflect.Field;import java.nio.ByteBuffer;import java.nio.MappedByteBuffer;import java.nio.channels.FileChannel;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import org.apache.hadoop.classification.InterfaceAudience;import org.apache.hadoop.classification.InterfaceStability;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.CommonConfigurationKeys;import org.apache.hadoop.fs.HardLink;import org.apache.hadoop.io.IOUtils;import org.apache.hadoop.io.SecureIOUtils.AlreadyExistsException;import org.apache.hadoop.util.NativeCodeLoader;import org.apache.hadoop.util.Shell;import org.apache.hadoop.util.PerformanceAdvisory;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import sun.misc.Unsafe;import com.google.common.annotations.VisibleForTesting;@InterfaceAudience.Private@InterfaceStability.Unstablepublic class NativeIO { public static class POSIX { // Flags for open() call from bits/fcntl.h public static final int O_RDONLY = 00; public static final int O_WRONLY = 01; public static final int O_RDWR = 02; public static final int O_CREAT = 0100; public static final int O_EXCL = 0200; public static final int O_NOCTTY = 0400; public static final int O_TRUNC = 01000; public static final int O_APPEND = 02000; public static final int O_NONBLOCK = 04000; public static final int O_SYNC = 010000; public static final int O_ASYNC = 020000; public static final int O_FSYNC = O_SYNC; public static final int O_NDELAY = O_NONBLOCK; public static final int POSIX_FADV_NORMAL = 0; public static final int POSIX_FADV_RANDOM = 1; public static final int POSIX_FADV_SEQUENTIAL = 2; public static final int POSIX_FADV_WILLNEED = 3; public static final int POSIX_FADV_DONTNEED = 4; public static final int POSIX_FADV_NOREUSE = 5; public static final int SYNC_FILE_RANGE_WAIT_BEFORE = 1; public static final int SYNC_FILE_RANGE_WRITE = 2; public static final int SYNC_FILE_RANGE_WAIT_AFTER = 4; private static final Log LOG = LogFactory.getLog(NativeIO.class); private static boolean nativeLoaded = false; private static boolean fadvisePossible = true; private static boolean syncFileRangePossible = true; static final String WORKAROUND_NON_THREADSAFE_CALLS_KEY = \"hadoop.workaround.non.threadsafe.getpwuid\"; static final boolean WORKAROUND_NON_THREADSAFE_CALLS_DEFAULT = true; private static long cacheTimeout = -1; private static CacheManipulator cacheManipulator = new CacheManipulator(); public static CacheManipulator getCacheManipulator() { return cacheManipulator; } public static void setCacheManipulator(CacheManipulator cacheManipulator) { POSIX.cacheManipulator = cacheManipulator; } @VisibleForTesting public static class CacheManipulator { public void mlock(String identifier, ByteBuffer buffer, long len) throws IOException { POSIX.mlock(buffer, len); } public long getMemlockLimit() { return NativeIO.getMemlockLimit(); } public long getOperatingSystemPageSize() { return NativeIO.getOperatingSystemPageSize(); } public void posixFadviseIfPossible(String identifier, FileDescriptor fd, long offset, long len, int flags) throws NativeIOException { NativeIO.POSIX.posixFadviseIfPossible(identifier, fd, offset, len, flags); } public boolean verifyCanMlock() { return NativeIO.isAvailable(); } } @VisibleForTesting public static class NoMlockCacheManipulator extends CacheManipulator { public void mlock(String identifier, ByteBuffer buffer, long len) throws IOException { LOG.info(\"mlocking \" + identifier); } public long getMemlockLimit() { return 1125899906842624L; } public long getOperatingSystemPageSize() { return 4096; } public boolean verifyCanMlock() { return true; } } static { if (NativeCodeLoader.isNativeCodeLoaded()) { try { Configuration conf = new Configuration(); workaroundNonThreadSafePasswdCalls = conf.getBoolean( WORKAROUND_NON_THREADSAFE_CALLS_KEY, WORKAROUND_NON_THREADSAFE_CALLS_DEFAULT); initNative(); nativeLoaded = true; cacheTimeout = conf.getLong( CommonConfigurationKeys.HADOOP_SECURITY_UID_NAME_CACHE_TIMEOUT_KEY, CommonConfigurationKeys.HADOOP_SECURITY_UID_NAME_CACHE_TIMEOUT_DEFAULT) * 1000; LOG.debug(\"Initialized cache for IDs to User/Group mapping with a \" + \" cache timeout of \" + cacheTimeout/1000 + \" seconds.\"); } catch (Throwable t) { PerformanceAdvisory.LOG.debug(\"Unable to initialize NativeIO libraries\", t); } } } public static boolean isAvailable() { return NativeCodeLoader.isNativeCodeLoaded() &amp;&amp; nativeLoaded; } private static void assertCodeLoaded() throws IOException { if (!isAvailable()) { throw new IOException(\"NativeIO was not loaded\"); } } public static native FileDescriptor open(String path, int flags, int mode) throws IOException; private static native Stat fstat(FileDescriptor fd) throws IOException; private static native void chmodImpl(String path, int mode) throws IOException; public static void chmod(String path, int mode) throws IOException { if (!Shell.WINDOWS) { chmodImpl(path, mode); } else { try { chmodImpl(path, mode); } catch (NativeIOException nioe) { if (nioe.getErrorCode() == 3) { throw new NativeIOException(\"No such file or directory\", Errno.ENOENT); } else { LOG.warn(String.format(\"NativeIO.chmod error (%d): %s\", nioe.getErrorCode(), nioe.getMessage())); throw new NativeIOException(\"Unknown error\", Errno.UNKNOWN); } } } } static native void posix_fadvise( FileDescriptor fd, long offset, long len, int flags) throws NativeIOException; static native void sync_file_range( FileDescriptor fd, long offset, long nbytes, int flags) throws NativeIOException; static void posixFadviseIfPossible(String identifier, FileDescriptor fd, long offset, long len, int flags) throws NativeIOException { if (nativeLoaded &amp;&amp; fadvisePossible) { try { posix_fadvise(fd, offset, len, flags); } catch (UnsupportedOperationException uoe) { fadvisePossible = false; } catch (UnsatisfiedLinkError ule) { fadvisePossible = false; } } } public static void syncFileRangeIfPossible( FileDescriptor fd, long offset, long nbytes, int flags) throws NativeIOException { if (nativeLoaded &amp;&amp; syncFileRangePossible) { try { sync_file_range(fd, offset, nbytes, flags); } catch (UnsupportedOperationException uoe) { syncFileRangePossible = false; } catch (UnsatisfiedLinkError ule) { syncFileRangePossible = false; } } } static native void mlock_native( ByteBuffer buffer, long len) throws NativeIOException; static void mlock(ByteBuffer buffer, long len) throws IOException { assertCodeLoaded(); if (!buffer.isDirect()) { throw new IOException(\"Cannot mlock a non-direct ByteBuffer\"); } mlock_native(buffer, len); } public static void munmap(MappedByteBuffer buffer) { if (buffer instanceof sun.nio.ch.DirectBuffer) { sun.misc.Cleaner cleaner = ((sun.nio.ch.DirectBuffer)buffer).cleaner(); cleaner.clean(); } } private static native long getUIDforFDOwnerforOwner(FileDescriptor fd) throws IOException; private static native String getUserName(long uid) throws IOException; public static class Stat { private int ownerId, groupId; private String owner, group; private int mode; public static final int S_IFMT = 0170000; /* type of file */ public static final int S_IFIFO = 0010000; /* named pipe (fifo) */ public static final int S_IFCHR = 0020000; /* character special */ public static final int S_IFDIR = 0040000; /* directory */ public static final int S_IFBLK = 0060000; /* block special */ public static final int S_IFREG = 0100000; /* regular */ public static final int S_IFLNK = 0120000; /* symbolic link */ public static final int S_IFSOCK = 0140000; /* socket */ public static final int S_IFWHT = 0160000; /* whiteout */ public static final int S_ISUID = 0004000; /* set user id on execution */ public static final int S_ISGID = 0002000; /* set group id on execution */ public static final int S_ISVTX = 0001000; /* save swapped text even after use */ public static final int S_IRUSR = 0000400; /* read permission, owner */ public static final int S_IWUSR = 0000200; /* write permission, owner */ public static final int S_IXUSR = 0000100; /* execute/search permission, owner */ Stat(int ownerId, int groupId, int mode) { this.ownerId = ownerId; this.groupId = groupId; this.mode = mode; } Stat(String owner, String group, int mode) { if (!Shell.WINDOWS) { this.owner = owner; } else { this.owner = stripDomain(owner); } if (!Shell.WINDOWS) { this.group = group; } else { this.group = stripDomain(group); } this.mode = mode; } @Override public String toString() { return \"Stat(owner='\" + owner + \"', group='\" + group + \"'\" + \", mode=\" + mode + \")\"; } public String getOwner() { return owner; } public String getGroup() { return group; } public int getMode() { return mode; } } public static Stat getFstat(FileDescriptor fd) throws IOException { Stat stat = null; if (!Shell.WINDOWS) { stat = fstat(fd); stat.owner = getName(IdCache.USER, stat.ownerId); stat.group = getName(IdCache.GROUP, stat.groupId); } else { try { stat = fstat(fd); } catch (NativeIOException nioe) { if (nioe.getErrorCode() == 6) { throw new NativeIOException(\"The handle is invalid.\", Errno.EBADF); } else { LOG.warn(String.format(\"NativeIO.getFstat error (%d): %s\", nioe.getErrorCode(), nioe.getMessage())); throw new NativeIOException(\"Unknown error\", Errno.UNKNOWN); } } } return stat; } private static String getName(IdCache domain, int id) throws IOException { Map&lt;Integer, CachedName&gt; idNameCache = (domain == IdCache.USER) ? USER_ID_NAME_CACHE : GROUP_ID_NAME_CACHE; String name; CachedName cachedName = idNameCache.get(id); long now = System.currentTimeMillis(); if (cachedName != null &amp;&amp; (cachedName.timestamp + cacheTimeout) &gt; now) { name = cachedName.name; } else { name = (domain == IdCache.USER) ? getUserName(id) : getGroupName(id); if (LOG.isDebugEnabled()) { String type = (domain == IdCache.USER) ? \"UserName\" : \"GroupName\"; LOG.debug(\"Got \" + type + \" \" + name + \" for ID \" + id + \" from the native implementation\"); } cachedName = new CachedName(name, now); idNameCache.put(id, cachedName); } return name; } static native String getUserName(int uid) throws IOException; static native String getGroupName(int uid) throws IOException; private static class CachedName { final long timestamp; final String name; public CachedName(String name, long timestamp) { this.name = name; this.timestamp = timestamp; } } private static final Map&lt;Integer, CachedName&gt; USER_ID_NAME_CACHE = new ConcurrentHashMap&lt;Integer, CachedName&gt;(); private static final Map&lt;Integer, CachedName&gt; GROUP_ID_NAME_CACHE = new ConcurrentHashMap&lt;Integer, CachedName&gt;(); private enum IdCache { USER, GROUP } public final static int MMAP_PROT_READ = 0x1; public final static int MMAP_PROT_WRITE = 0x2; public final static int MMAP_PROT_EXEC = 0x4; public static native long mmap(FileDescriptor fd, int prot, boolean shared, long length) throws IOException; public static native void munmap(long addr, long length) throws IOException; } private static boolean workaroundNonThreadSafePasswdCalls = false; public static class Windows { public static final long GENERIC_READ = 0x80000000L; public static final long GENERIC_WRITE = 0x40000000L; public static final long FILE_SHARE_READ = 0x00000001L; public static final long FILE_SHARE_WRITE = 0x00000002L; public static final long FILE_SHARE_DELETE = 0x00000004L; public static final long CREATE_NEW = 1; public static final long CREATE_ALWAYS = 2; public static final long OPEN_EXISTING = 3; public static final long OPEN_ALWAYS = 4; public static final long TRUNCATE_EXISTING = 5; public static final long FILE_BEGIN = 0; public static final long FILE_CURRENT = 1; public static final long FILE_END = 2; public static final long FILE_ATTRIBUTE_NORMAL = 0x00000080L; public static void createDirectoryWithMode(File path, int mode) throws IOException { createDirectoryWithMode0(path.getAbsolutePath(), mode); } private static native void createDirectoryWithMode0(String path, int mode) throws NativeIOException; public static native FileDescriptor createFile(String path, long desiredAccess, long shareMode, long creationDisposition) throws IOException; public static FileOutputStream createFileOutputStreamWithMode(File path, boolean append, int mode) throws IOException { long desiredAccess = GENERIC_WRITE; long shareMode = FILE_SHARE_READ | FILE_SHARE_WRITE; long creationDisposition = append ? OPEN_ALWAYS : CREATE_ALWAYS; return new FileOutputStream(createFileWithMode0(path.getAbsolutePath(), desiredAccess, shareMode, creationDisposition, mode)); } private static native FileDescriptor createFileWithMode0(String path, long desiredAccess, long shareMode, long creationDisposition, int mode) throws NativeIOException; public static native long setFilePointer(FileDescriptor fd, long distanceToMove, long moveMethod) throws IOException; private static native String getOwner(FileDescriptor fd) throws IOException; public static enum AccessRight { ACCESS_READ (0x0001), // FILE_READ_DATA ACCESS_WRITE (0x0002), // FILE_WRITE_DATA ACCESS_EXECUTE (0x0020); // FILE_EXECUTE private final int accessRight; AccessRight(int access) { accessRight = access; } public int accessRight() { return accessRight; } }; private static native boolean access0(String path, int requestedAccess); public static boolean access(String path, AccessRight desiredAccess) throws IOException { return true; } public static native void extendWorkingSetSize(long delta) throws IOException; static { if (NativeCodeLoader.isNativeCodeLoaded()) { try { initNative(); nativeLoaded = true; } catch (Throwable t) { PerformanceAdvisory.LOG.debug(\"Unable to initialize NativeIO libraries\", t); } } } } private static final Log LOG = LogFactory.getLog(NativeIO.class); private static boolean nativeLoaded = false; static { if (NativeCodeLoader.isNativeCodeLoaded()) { try { initNative(); nativeLoaded = true; } catch (Throwable t) { PerformanceAdvisory.LOG.debug(\"Unable to initialize NativeIO libraries\", t); } } } public static boolean isAvailable() { return NativeCodeLoader.isNativeCodeLoaded() &amp;&amp; nativeLoaded; } private static native void initNative(); static long getMemlockLimit() { return isAvailable() ? getMemlockLimit0() : 0; } private static native long getMemlockLimit0(); static long getOperatingSystemPageSize() { try { Field f = Unsafe.class.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); Unsafe unsafe = (Unsafe)f.get(null); return unsafe.pageSize(); } catch (Throwable e) { LOG.warn(\"Unable to get operating system page size. Guessing 4096.\", e); return 4096; } } private static class CachedUid { final long timestamp; final String username; public CachedUid(String username, long timestamp) { this.timestamp = timestamp; this.username = username; } } private static final Map&lt;Long, CachedUid&gt; uidCache = new ConcurrentHashMap&lt;Long, CachedUid&gt;(); private static long cacheTimeout; private static boolean initialized = false; private static String stripDomain(String name) { int i = name.indexOf('\\\\'); if (i != -1) name = name.substring(i + 1); return name; } public static String getOwner(FileDescriptor fd) throws IOException { ensureInitialized(); if (Shell.WINDOWS) { String owner = Windows.getOwner(fd); owner = stripDomain(owner); return owner; } else { long uid = POSIX.getUIDforFDOwnerforOwner(fd); CachedUid cUid = uidCache.get(uid); long now = System.currentTimeMillis(); if (cUid != null &amp;&amp; (cUid.timestamp + cacheTimeout) &gt; now) { return cUid.username; } String user = POSIX.getUserName(uid); LOG.info(\"Got UserName \" + user + \" for UID \" + uid + \" from the native implementation\"); cUid = new CachedUid(user, now); uidCache.put(uid, cUid); return user; } } public static FileInputStream getShareDeleteFileInputStream(File f) throws IOException { if (!Shell.WINDOWS) { return new FileInputStream(f); } else { FileDescriptor fd = Windows.createFile( f.getAbsolutePath(), Windows.GENERIC_READ, Windows.FILE_SHARE_READ | Windows.FILE_SHARE_WRITE | Windows.FILE_SHARE_DELETE, Windows.OPEN_EXISTING); return new FileInputStream(fd); } } public static FileInputStream getShareDeleteFileInputStream(File f, long seekOffset) throws IOException { if (!Shell.WINDOWS) { RandomAccessFile rf = new RandomAccessFile(f, \"r\"); if (seekOffset &gt; 0) { rf.seek(seekOffset); } return new FileInputStream(rf.getFD()); } else { FileDescriptor fd = NativeIO.Windows.createFile( f.getAbsolutePath(), NativeIO.Windows.GENERIC_READ, NativeIO.Windows.FILE_SHARE_READ | NativeIO.Windows.FILE_SHARE_WRITE | NativeIO.Windows.FILE_SHARE_DELETE, NativeIO.Windows.OPEN_EXISTING); if (seekOffset &gt; 0) NativeIO.Windows.setFilePointer(fd, seekOffset, NativeIO.Windows.FILE_BEGIN); return new FileInputStream(fd); } } public static FileOutputStream getCreateForWriteFileOutputStream(File f, int permissions) throws IOException { if (!Shell.WINDOWS) { try { FileDescriptor fd = NativeIO.POSIX.open(f.getAbsolutePath(), NativeIO.POSIX.O_WRONLY | NativeIO.POSIX.O_CREAT | NativeIO.POSIX.O_EXCL, permissions); return new FileOutputStream(fd); } catch (NativeIOException nioe) { if (nioe.getErrno() == Errno.EEXIST) { throw new AlreadyExistsException(nioe); } throw nioe; } } else { try { FileDescriptor fd = NativeIO.Windows.createFile(f.getCanonicalPath(), NativeIO.Windows.GENERIC_WRITE, NativeIO.Windows.FILE_SHARE_DELETE | NativeIO.Windows.FILE_SHARE_READ | NativeIO.Windows.FILE_SHARE_WRITE, NativeIO.Windows.CREATE_NEW); NativeIO.POSIX.chmod(f.getCanonicalPath(), permissions); return new FileOutputStream(fd); } catch (NativeIOException nioe) { if (nioe.getErrorCode() == 80) { throw new AlreadyExistsException(nioe); } throw nioe; } } } private synchronized static void ensureInitialized() { if (!initialized) { cacheTimeout = new Configuration().getLong(\"hadoop.security.uid.cache.secs\", 4*60*60) * 1000; LOG.info(\"Initialized cache for UID to User mapping with a cache\" + \" timeout of \" + cacheTimeout/1000 + \" seconds.\"); initialized = true; } } public static void renameTo(File src, File dst) throws IOException { if (!nativeLoaded) { if (!src.renameTo(dst)) { throw new IOException(\"renameTo(src=\" + src + \", dst=\" + dst + \") failed.\"); } } else { renameTo0(src.getAbsolutePath(), dst.getAbsolutePath()); } } public static void link(File src, File dst) throws IOException { if (!nativeLoaded) { HardLink.createHardLink(src, dst); } else { link0(src.getAbsolutePath(), dst.getAbsolutePath()); } } private static native void renameTo0(String src, String dst) throws NativeIOException; private static native void link0(String src, String dst) throws NativeIOException; public static void copyFileUnbuffered(File src, File dst) throws IOException { if (nativeLoaded &amp;&amp; Shell.WINDOWS) { copyFileUnbuffered0(src.getAbsolutePath(), dst.getAbsolutePath()); } else { FileInputStream fis = null; FileOutputStream fos = null; FileChannel input = null; FileChannel output = null; try { fis = new FileInputStream(src); fos = new FileOutputStream(dst); input = fis.getChannel(); output = fos.getChannel(); long remaining = input.size(); long position = 0; long transferred = 0; while (remaining &gt; 0) { transferred = input.transferTo(position, remaining, output); remaining -= transferred; position += transferred; } } finally { IOUtils.cleanup(LOG, output); IOUtils.cleanup(LOG, fos); IOUtils.cleanup(LOG, input); IOUtils.cleanup(LOG, fis); } } } private static native void copyFileUnbuffered0(String src, String dst) throws NativeIOException;}","link":"/2020/06/29/BigData/MapReduce/MapReduce%E5%9C%A8Windows%E4%B8%8B%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/"},{"title":"MapReduce案例:可能认识的人","text":"可能认识的人A认识B，B认识C而A不认识C则A与C是可能认识的人。 使用两个MapReduce实现这个功能。 第一次mapreduce分别统计每个人直接认识的人，输出的数据是A：B C D。从这一行数据中可以知道A与BCD是直接认识的。BCD之间存在可能认识的关系。所以要做的就是把直接认识的两人标记出来。留下的便是可能认识的人。 在第二个map中将这些数据进行两两组合，每一个组合都是一个关系对（A-B,B-C…）。如果只是组合会出现A-B B-A这种互逆关系对，这种关系的意义是等价的，所以通过CompareTo()方法进行比较统一成一种关系对。在生成关系对的同时标记这对关系是否已经是好友。如果已经认识了则标记为true否则为false。将关系对作为key，标记作为value输出。（通过第一个mapreduce的数据可以知道每一行数据的key（A）和value（BCD）中的每一个人都是直接认识的所以都标记为true（A-B:true A-C:true A-D:true）。） 在reduce阶段进行验证，如果一个关系对存在标记true就说明是直接认识的关系，不进行统计。相反全为false就说明这两人是可能认识的关系，写出到文件中。 输入数据: tom rose tom jim tom smith tom lucy rose tom rose lucy rose smith jim tom jim lucy smith jim smith tom smith rose第一个Mapper:拆分数据将每一个人认识的人统计出来 A:B,A:C 输出Text,Text 123456789public class RelationMapper01 extends Mapper&lt;LongWritable, Text,Text,Text&gt; { @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String[] str = value.toString().split(\" \"); context.write(new Text(str[0]),new Text(str[1])); }} 第一个Reducer:统计每个人认识的人 A:B C D,写出Text,Text 1234567891011121314public class RelationReducer01 extends Reducer&lt;Text,Text,Text,Text&gt; { @Override protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException { StringBuffer stringBuffer = new StringBuffer(); for (Text v:values){ stringBuffer.append(v.toString()); stringBuffer.append(\"\\t\"); } context.write(key,new Text(String.valueOf(stringBuffer))); }} 输出数据: jim lucy tom rose smith lucy tom smith rose tom jim tom lucy smith jim rose 第二个Mapper:拆分数据，生成关系对。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class RelationMapper02 extends Mapper&lt;LongWritable, Text,Text, BooleanWritable&gt; { @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String[] person = value.toString().split(\"\\t\"); StringBuffer stringBuffer = new StringBuffer(); //a认识的人 for (int i=1;i&lt;person.length;i++){ if (person[0].compareTo(person[i])&lt;0){ //比较字符串 确保AB BA是同一对关系 stringBuffer.append(person[0]) .append(\" \") .append(person[i]); //拼接字符串 }else if (person[0].compareTo(person[i])&gt;0){ stringBuffer.append(person[i]) .append(\" \") .append(person[0]); }else{ continue; } context.write(new Text(String.valueOf(stringBuffer)), new BooleanWritable(true)); stringBuffer.setLength(0);//清空stringBuffer } //其他人的关系 if (person.length&lt;3) return; for (int i=1;i&lt;person.length;i++){ for (int j=i+1;j&lt;person.length;j++){ if (person[i].compareTo(person[j])&lt;0){//比较 stringBuffer.append(person[i]) .append(\" \") .append(person[j]); }else if (person[i].compareTo(person[j])&gt;0){ stringBuffer.append(person[j]) .append(\" \") .append(person[i]); }else { continue; } context.write(new Text(String.valueOf(stringBuffer)), new BooleanWritable(false)); stringBuffer.setLength(0);//清空stringBuffer } } }} 第二个Reducer：验证关系。 123456789101112public class RelationReduce02 extends Reducer&lt;Text, BooleanWritable,Text, NullWritable&gt; { @Override protected void reduce(Text key, Iterable&lt;BooleanWritable&gt; values, Context context) throws IOException, InterruptedException { for (BooleanWritable b:values){ if (b.get()) return; //如果存在true 说明两人原本就是认识的那么直接结束reduce阶段不统计两人关系 } //否则两人values全部为false 说明两人可能认识 输出两人的关系 context.write(key,NullWritable.get()); }} 输出数据: jim rose lucy smith","link":"/2020/07/01/BigData/MapReduce/MapReduce%E6%A1%88%E4%BE%8B01/"},{"title":"Zookeeper集群","text":"一、概述 zookeeper集群启动后，所有节点（服务器）都会进入选举状态，所有节点都会推荐自己成为leader 每一个节点都会将自己的选举信息发送给其他节点，节点之间会进行比较，经过多轮比较之后最终胜出的节点成为leader 二、集群特性 过半性：过半选举、过半服务、过半操作 数据一致性：访问任意一个节点，获取到的数据时相同的。 原子性：一个请求到了Zookeeper上之后，要么所有节点都执行要么都不执行 可靠性：保证集群的高可用。 顺序性：leader按照什么顺序接收。的请求，那么follower就会按照什么顺序执行请求。 实时性：在网络条件较好的情况下，可以实时监控Zookeeper的变化。 三、选举机制 选举信息 a. 节点的最大事务id（最大事务id越大意味着这个节点存储的数据越多） b. 选举编号 - myid(我们在配置过程中给的编号) c. 逻辑时钟值（记录选举轮次） 比较原则 先比较两个节点的最大事务id，谁大谁赢 。 如果事务id一致，则比较myid，谁大谁赢 。 如果一个节点胜过一半及以上的节点的时候，这个节点会被选举为leader - 过半性。 一个Zookeeper集群已经选举出来leader，为了集群的稳定性而言，无论新添的节点的事务id或者myid是多少，都只能成为follower 。 如果leader产生宕机，那么Zookeeper会重新选举出一个新的leader 。 如果集群中出现多个leader，这种现象称之为脑裂 。 Zookeeper中脑裂产生的条件 ： 集群产生分裂(网络故障) 分裂之后还进行了选举 在Zookeeper集群中，如果存活的节点个数不足一半，则剩余的节点不选举也不对外服务 - 过半性 。 Zookeeper中的节点个数一般是奇数个 - Zookeeper集群的节点个数最少是3个。 Zookeeper会对每一任leader分配一个自增的编号，这个编号称之为epochid。一旦Zookeeper发现存在一个以上的leader的时候，那么会将epocid较小的节点的状态切换为follower。 四、zookeeper集群中的角色 leader 负责写数据，一个zookeeper集群只有一个leader节点。 客户端提交请求之后,先发送到leader,leader作为接收者,广播到每个server。 follower 转发事务请求给leader，处理非事务请求。 参与选举和投票。 observer 在集群中，一个节点一旦被设置为observer，那么这个节点的状态就不会再改变。 observer既不参与选举也不参与投票（原子广播）。但是observer会监听选举或者投票结果，然后根据结果产生对应的操作。（observer是没有选举权的follower） 一个集群中，一般会将90%~97%的节点设置为observer，这么做的目的是为了提高选举和投票效率，减少网络影响。 在zookeeper集群中，observe的存活与否并不影响集群的服务。例如假设一个集群中有21个节点，其中有一个leader，6个follower，14个observe，那么即使14个observe全部宕机，集群依然对外服务。但是有4个follower宕机那么集群会停止对外服务，因为此时将不存在过半性–过半性是针对有选举权的节点。 配置观察者 peerType=observer","link":"/2020/06/25/BigData/Zookeeper/Zookeeper%E9%9B%86%E7%BE%A4/"},{"title":"ZAB协议","text":"一、概述 ZAB（Zookeeper Atomic Broadcast）协议是一套专门为zookeeper设计的进行原子广播和崩溃恢复的协议。 ZAB是基于2PC算法来进行设计的并且利用过半性+PAXOS算法进行了改进。 二、原子广播 作用：保证节点之间数据的一致性，在zookeeper中，访问任意一个节点获取到的数据都是相同的。 原子广播基于2PC算法设计，利用过半性来改进 2PC（Two Phase Commit）二阶段提交 要么请求提交要么请求中止，核心思想是一票否决。 请求阶段：协调者接收到请求不能立即决定是否立即执行，而是需要将请求发送给每一个参与者，等待参与者的反馈信息。 提交阶段：如果协调者收到所有的参与者返回的yes，那么协调者就会命令每一个参与者执行这个请求。 中止阶段：如果协调者没有收到所有参与者返回的yes，那么协调者就会命令所有的参与者放弃这个请求。 2PC算法设计和实现过程相对简单，但是容易受外界环境影响，对网络环境的容错性相对较差。 原子广播过程： leader接收到请求之后会先将这个请求记录到本地的日志文件log.xxxx中。log.xxxx的存储位置由dataDir属性来决定。 如果记录失败则leader会认为这个请求不能执行，直接报错。 如果记录成功则leader会把请求放到队列中发送给每一个follower。 follower在收到队列之后，也会将请求从队列中依次取出然后一一记录到本地的日志文件log.xxxx中。 如果follower认为这个请求可以执行那么会返回给leader一个yes 如果follower认为这个请求不可以执行会返回no 判断是否执行 如果leader收到半数及以上节点返回yes那么就认为这个请求可以执行，就会要求所有的follower执行这个请求。（提交） 如果没有收到到半数yes则认为这个请求不能执行，就会要求所有的follower删除之前的记录。（回滚） 如果follower记录日志失败，leader却还要求执行这个请求，此时follower会给leader发出请求，leader收到请求之后会把操作放到队列之中发送给follower，follower会再次试图记录日志再次执行；如果再次记录失败，会重复发请求。因此，如果在维护集群时发现follower频繁给leader发请求，那么说明这个follower可能产生问题（无法记录日志–文件被占用（会自己解决），磁盘坏道，磁盘已满）。 三、崩溃恢复 在Zookeeper集群中，当leader丢失的时候，集群不会停止服务而是会选举产生一个新的leader，这个过程称之为崩溃恢复。 作用：避免单点故障，保证集群的可用性。 当某一个节点重新连入集群后，这个节点会先找到自己的最大事务id，然后会给leader发送请求。leader收到请求之后会去比较事务id是否一致，如果不一致leader会将缺失的事务放到队列中返回给该节点要求补齐。 zookeeper会对每一任leader分配一个递增的epochid。当leader上任之后，这个leader会将自己的epochid分发给每一个follower，而follower收到之后会存储到本地文件acceptedEpoch中。集群中事务id是由64位二进制（16位十六进制）数字组成，其中高32位是epochid,低32位是实际的事务id。例如0x200000009表示第二任leader执行的第九个写操作。","link":"/2020/06/25/BigData/Zookeeper/ZAB%E5%8D%8F%E8%AE%AE/"},{"title":"YARN","text":"YARN YARN(Yet Another Resource Negotiator，迄今另一个资源协调者)是Hadoop2.0中提供的一套用于资源管理和任务调度的机制，也正因为这套机制的出现，导致Hadoop1.0和Hadoop2.0不兼容。 YARN出现的原因: 内因：在Hadoop1.0中，JobTrakcer既要对外接收任务，还要对内管理TaskTracker以及分配任务，并且JobTracker还需要监控TaskTracker的任务执行情况，这就导致JobTracker要负责的任务非常多，从而成为整个集群的性能瓶颈。并且Hadoop1.0中，JobTracker只允许存在一个，就意味着存在单点故障。在Hadoop1.0的官方文档中，给定，一个JobTracker最多能管理4000个TaskTracker，多一个都会导致效率成倍下降甚至导致JobTracker的崩溃 外果：Hadoop作为大数据的基本生态框架，有很多的计算框架(Pig，Tez，Spark等)基于它来使用。在Hadoop1.0中，各个计算框架之间会直接各自抢占Hadoop的资源，那么就导致框架之间的资源占用会产生冲突","link":"/2020/06/25/BigData/YARN/"}],"tags":[{"name":"大数据","slug":"大数据","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"学习笔记","slug":"学习笔记","link":"/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"MapReduce","slug":"MapReduce","link":"/tags/MapReduce/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"}],"categories":[{"name":"MapReduce","slug":"MapReduce","link":"/categories/MapReduce/"},{"name":"Hadoop","slug":"Hadoop","link":"/categories/Hadoop/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/categories/Zookeeper/"}]}