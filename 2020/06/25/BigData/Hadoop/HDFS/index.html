<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>HDFS - Azurlin&#039;s blog</title><meta description="概述 HDFS（Hadoop Distributed File System）是hadoop提供的一套用于进行分布式文件存储的系统。 HDFS是doug仿照Google的GFS（Google File System）来实现的。 云主机启动hadoop 通过本地浏览器访问IP:50070监控hadoop。"><meta property="og:type" content="blog"><meta property="og:title" content="HDFS"><meta property="og:url" content="http://yoursite.com/2020/06/25/BigData/Hadoop/HDFS/"><meta property="og:site_name" content="Azurlin&#039;s blog"><meta property="og:description" content="概述 HDFS（Hadoop Distributed File System）是hadoop提供的一套用于进行分布式文件存储的系统。 HDFS是doug仿照Google的GFS（Google File System）来实现的。 云主机启动hadoop 通过本地浏览器访问IP:50070监控hadoop。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:published_time" content="2020-06-25T07:16:39.000Z"><meta property="article:modified_time" content="2020-07-01T07:58:37.075Z"><meta property="article:author" content="Azurlin"><meta property="article:tag" content="大数据"><meta property="article:tag" content="学习笔记"><meta property="article:tag" content="Hadoop"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2020/06/25/BigData/Hadoop/HDFS/"},"headline":"Azurlin's blog","image":["http://yoursite.com/img/og_image.png"],"datePublished":"2020-06-25T07:16:39.000Z","dateModified":"2020-07-01T07:58:37.075Z","author":{"@type":"Person","name":"Azurlin"},"description":"概述 HDFS（Hadoop Distributed File System）是hadoop提供的一套用于进行分布式文件存储的系统。 HDFS是doug仿照Google的GFS（Google File System）来实现的。 云主机启动hadoop 通过本地浏览器访问IP:50070监控hadoop。"}</script><link rel="canonical" href="http://yoursite.com/2020/06/25/BigData/Hadoop/HDFS/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Azurlin&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Azurlin"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-06-25T07:16:39.000Z" title="2020-06-25T07:16:39.000Z">2020-06-25</time><span class="level-item"><a class="link-muted" href="/categories/Hadoop/">Hadoop</a></span><span class="level-item">30 分钟 读完 (大约 4494 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">HDFS</h1><div class="content"><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ol>
<li>HDFS（Hadoop Distributed File System）是hadoop提供的一套用于进行分布式文件存储的系统。</li>
<li>HDFS是doug仿照Google的GFS（Google File System）来实现的。</li>
<li>云主机启动hadoop 通过本地浏览器访问IP:50070监控hadoop。</li>
</ol>
<a id="more"></a>

<h2 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h2><h3 id="基本概述"><a href="#基本概述" class="headerlink" title="基本概述"></a>基本概述</h3><ol>
<li>随着数据量的不断增大，单机存储方式已经不能够适应生产环境，所以我们需要引入分布式存储。</li>
<li>HDFS是一个典型的MS结构：主节点是NameNode，从节点是DataNode。</li>
<li>在HDFS中存储数据时，会对数据进行切分，切成不同的数据块Block。</li>
<li>HDFS会对存入其中的Block进行备份，这个备份称之为副本。HDFS中默认的副本策略是3，既需要复制2次加上原来的副本构成3个副本。</li>
<li>HDFS提供了一套类似于linux的文件系统，即仿照Linux，允许用户产生不同的目录，同时为不同的路径设计权限。根路径是/。</li>
</ol>
<h3 id="Block-数据块"><a href="#Block-数据块" class="headerlink" title="Block 数据块"></a>Block 数据块</h3><ol>
<li>Block是HDFS中的基本存储单位，即所有的数据都是以block形存储的。</li>
<li>Block默认大小不超过128M(可以通过属性 dfsblocksize调节–hdsf/site.xml 单位是字节默认是)。</li>
<li>如果上传的文件不足一个Block大小，那么这个文件是多大对应的Block就是多大。例如一个文件15M那么对应的Block就是15M。</li>
<li>每一个Block都会分配一个编号BlockID。</li>
<li>HDFS会记录每一个Block上传的时间，但是并不是直接记录时间，而是给时间戳一个编号Generation Stamp。</li>
<li><strong>Block的意义</strong><pre><code>a. 能够存储超大文件
b. 能够迅速的备份</code></pre></li>
<li>一个DataNode可能会存储很多个Block。</li>
</ol>
<h3 id="NameNode-主节点"><a href="#NameNode-主节点" class="headerlink" title="NameNode 主节点"></a>NameNode 主节点</h3><ol>
<li>NameNode是HDFS中的主节点。</li>
<li><strong>作用：</strong>管理DataNode，存储元数据。</li>
<li>元数据是对数据描述的数据，元数据中不包含具体的数据内容 -账本</li>
<li><strong>元数据主要包含</strong><pre><code>1) 文件的上传路径
2) 上传的用户名以及对应的权限
3) 文件的大小
4) Block的大小
5) 文件和BlockID的映射关系
6) BlockID和DataNode的映射关系
7) 文件的副本数量</code></pre></li>
<li><strong>NameNode会将元数据维系在磁盘以及内存中</strong><pre><code>1) 在磁盘中是为了崩溃恢复
2) 在内存中是为了读写快</code></pre></li>
<li>元数据的存储位置有属性hadoop.tmp.dir来决定，如果不配置则默认放在/tmp下，所以需要更改路径。</li>
<li><strong>与元数据相关的文件</strong><pre><code>○ edits：操作文件，用于记录HDFS的写操作。
○ fsimage：元数据（映像）文件，用于记录HDFS的元数据。</code></pre></li>
<li>当NameNode收到写操作的时候，先将写操作记录到edits_inprogress文件中，如果记录成功，则修改内存中的元数据，如果修改成功，则给客户端返回一个ack信号表示成功。注意，此时fsimage文件中的元数据并没有发生改变。</li>
<li>当edits_inprogress文件达到指定条件的时候，产生一个新的edits_inprogress用来记录新的写操作，同时原来的edits_inprogress会滚动改名为edits，新生成的edits文件会将其中写操作一一取出重新执行来更新fsimage中的元数据。</li>
<li><strong>edits_inprogress滚动条件</strong><br>○ 空间：edits_inprogress文件达到指定大小(默认是64M，通过属性fs.checkpoint.size来调节，配置在core-site.xml，单位是字节)之后，会滚动生成edits。<br>○ 时间：当距离上一次滚动的间隔时间达到指定大小（默认是1h，通过属性fs.checkpoint.period来调节，配置在core-site.xml，单位是秒）的时候，eidts——inprogress也会滚动。<br>○ 重启：当NameNode重启的时候，自动触发edits_inprogress文件的滚动<br>○ 强制滚动：通过hadoop dfadmin -rollEdits来进行强制滚动。</li>
<li>NameNode通过心跳机制来管理DataNode。DataNode定时给NameNode发送心跳信息。</li>
<li>心跳信息通过RPC方式发送。</li>
<li>心跳间隔时间默认为3s，通过属性dfs.heartbeat.interval来调节，单位是秒。</li>
<li>如果NameNode超过10min没有收到DataNode的心跳，则认为这个DataNode已经lost（丢失），那么就会将这个DataNode上的数据备份到其他节点上保证副本数量。</li>
<li><strong>心跳信息</strong><br>○ <strong>clusterid</strong>：集群编号。在NameNode被格式化（hadoop namenode -format）的时候，自动计算产生一个clusterid。NameNode会将clusterid发送给每一个DataNode，DataNode收到clusterid之后会存储在本地。之后DataNode和NameNode的每一次通信都需要携带clusterid。NameNode在收到DataNode的信号之后会先校验clusterid是否一致，如果不一致则直接抛弃。如果一致，NameNode才会处理DataNode的请求。DataNode只接受一次clusterid。NameNode每次格式化都会产生一个新的clusterid，如果NameNode被格式化多次，就会发现NameNode联系不上DataNode，此时通过jps命令查看，发现要么缺少NameNode要么缺少DataNode。<br>○ <strong>DataNode的节点状态</strong>：预服役、服役、预退役。<br>○ <strong>Block的存储信息</strong></li>
<li><strong>安全模式（safe mode）</strong><br>1) 当NameNode产生重启的时候，首先会触发edits_inprogress文件的滚动，产生edits文件之后会更新fsimage文件中的元数据。<br>2) 当fsimage文件中的元数据更新完成之后，NameNode会将fsimage中的元数据加载到内存中。<br>3) 元数据加载完成之后，NameNode等待DataNode的心跳。<br>4) 如果NameNode没有收到心跳，则会试图备份这个DataNode上的数据到其他的DataNode上。<br>5) NameNode在收到DataNode的心跳之后会进行校验。校验Block信息（Block大小、数量等）。<br>6) 如果校验失败则NameNode会试图恢复这个数据；恢复完成之后会再次校验。<br>7) 如果所有的DataNode都校验成功，则会自动退出安全模式。</li>
<li>在安全模式中，HDFS不对外提供写服务。</li>
<li>NameNode在重启时会自动进入安全模式。如果在进行操作的时候发现HDFS处在安全模式中，那么需要等待一会儿，等他自动退出安全模式。如果在合理的时间内，HDFS没有退出安全模式，那么说明数据产生了无法挽回的丢失。此时只能强制退出安全模式（hadoop dfsadmin -safemode leave）。</li>
<li>正因为安全模式和副本放置策略的存在，所以在伪分布式中副本数量必须为1 - 副本数量不能超过节点数量。</li>
<li>NameNode在HDFS中处于核心地位，但是在Hadoop1.0，NameNode只能由1个，在Hadoop2.0中通过舍弃SecondaryNameNode可以允许存在2个NameNode，在Hadoop3.0中，NameNode的个数不再限制。</li>
</ol>
<h3 id="副本放置策略"><a href="#副本放置策略" class="headerlink" title="副本放置策略"></a>副本放置策略</h3><ol>
<li>在HDFS中，默认采用多副本机制，默认副本数量为3，通过dfs.replication属性来进行设置，配置在hdfs-site.xml文件中。</li>
<li><strong>放置策略</strong><br> a. 第一个副本<pre><code>1) 如果是集群内部上传，则谁上传第一个副本就放在谁身上。
2) 如果是集群外部上传，则谁相对空闲就放到谁身上。</code></pre> b. 第二个副本<pre><code>1) Hadoop2.7之前：第二个副本是放在和第一个副本不同机架的节点上
2) Hadoop2.7开始：第二个副本是放在和第一个副本相同的机架的节点上</code></pre> c. 第三个副本<pre><code>1) Hadoop2.7之前：第三个副本是放在和第二个副本相同机架的节点上
2) Hadoop2.7开始：第三个副本是放在和第二个副本不同机架的节点上</code></pre> d. 更多副本：放置在相对空闲的DataNode上。</li>
</ol>
<h3 id="机架感知策略"><a href="#机架感知策略" class="headerlink" title="机架感知策略"></a>机架感知策略</h3><ol>
<li>默认情况下，Hadoop的机架感知策略没有被启用，所以HDFS在存放数据的时候都是选择相对空闲的节点来存储。</li>
<li>通过脚本文件来指定机架感知。脚本文件可以是Shell/Python语言编写。</li>
<li>通过一个Map来指定机架，其中将主机的主机名或者IP作为Map的键，然后将机架名作为值。只要值一样，就意味着这些键对应的主机就在一个机架上 - 这个Map称之为逻辑机架。</li>
<li>理论上可以将不同的物理机架上的节点配置在相同的逻辑机架上（只要保持值相同即可），但是这样不利于管理，所以实际过程中，一般是将统一个物理机架上的节点配置在同一个逻辑机架上。</li>
</ol>
<h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><ol>
<li>SecondaryNameNode不是NameNode的备份，仅仅是辅助NameNode完成edits文件的滚动和fsimage文件的更新。</li>
<li>如果存在SecondaryNameNode，那么edits文件的滚动和fsimage文件的更新是发生在SecondaryNameNode上。如果不存在，则上述过程发生在NameNode。</li>
<li>到目前为止，HDFS2.0只支持2种结构。<pre><code>a. 1个NameNode+1个SecondaryNameNode+多个DataNode。
b. 2个NameNode（构成备份）+多个DataNode。</code></pre></li>
<li>考虑到NameNode的核心地位，所以需要考虑NameNode的备份问题，所以一般采用的是第二种结构：2个NameNode(Active状态+Standby备份状态)+多个DataNode。</li>
</ol>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><ol>
<li><p><strong>作用：</strong>存储数据，数据是以Block形式存在。</p>
</li>
<li><p>DataNode将数据存储在磁盘上（数据多），在磁盘上的存储位置由属性hadoop.tmp.dir来决定。</p>
</li>
<li><p>DataNode会为每一个Block生成一个.meta文件，.meta实际上是对Block的校验（.meta中存储了一个校验值，这个校验值是根据Block大小、生成时间、存储内容等信息进行非对称加密计算出来的一个整数）。DataNode给NameNode发送心跳的时候是包含这个加密值的，如果更改了Block内容，那么.meta文件中的内容也会重新计算。</p>
</li>
<li><p>DataNode通过心跳机制来向NameNode发送信息。</p>
</li>
</ol>
<h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>hadoop fs -put /home/a.txt /b.txt</td>
<td>将/home/a.txt上传到HDFS的根目录下并且重命名为b.txt</td>
</tr>
<tr>
<td>hadoop fs -mkdir /log</td>
<td>在HDFS的/下创建子目录log</td>
</tr>
<tr>
<td>hadoop fs -get /a.txt /home</td>
<td>将HDFS的/a.txt下载到本地的/home目录下</td>
</tr>
<tr>
<td>hadoop fs -mv /a.txt /b.txt</td>
<td>重命名</td>
</tr>
<tr>
<td>hadoop fs -mv /a.txt /log/a.txt</td>
<td>剪切</td>
</tr>
<tr>
<td>hadoop fs -cp /a.txt /c.txt</td>
<td>复制</td>
</tr>
<tr>
<td>hadoop fs -chmod 777 /a.txt</td>
<td>修改权限</td>
</tr>
<tr>
<td>hadoop fs -ls /</td>
<td>查看/下的子文件和子目录</td>
</tr>
<tr>
<td>hadoop fs -lsr /</td>
<td>递归查看</td>
</tr>
<tr>
<td>hadoop fs -rm /a.txt</td>
<td>删除文件</td>
</tr>
<tr>
<td>hadoop fs -rmdir /test</td>
<td>删除目录，要求目录为空</td>
</tr>
<tr>
<td>hadoop fs -rmr /log</td>
<td>递归删除目录</td>
</tr>
</tbody></table>
<h3 id="回收站机制"><a href="#回收站机制" class="headerlink" title="回收站机制"></a>回收站机制</h3><ol>
<li>在HDFS中，回收站机制默认是不开启的（即默认值为0），所以一个文件如果被删除，会立即从HDFS上移除，这个操作不可撤销。</li>
<li>回收站机制需要core-site.xml中配置。</li>
</ol>
<h2 id="DFS目录"><a href="#DFS目录" class="headerlink" title="DFS目录"></a>DFS目录</h2><ol>
<li>DFS目录的位置实际上由hadoop.tmp.dir来指定，本质上是HDFS的数据目录 </li>
<li>DFS目录是在NameNode被格式化(hadoop namenode -format)的时候产生的 </li>
<li>DFS的子目录 - 实际过程中，三个子目录应该是出现在不同的节点上 <ul>
<li>data：DataNode的数据目录 </li>
<li>name：NameNode的数据目录 </li>
<li>namesecondary：SecondaryNameNode的数据目录 </li>
</ul>
</li>
<li>当对应进程开启的时候，HDFS对应的子目录下回出现in_use.lock。 in_use.lock标记已经开启进程，防止重复开启。 </li>
<li>在HDFS第一次启动的时候，启动之后1min，edits_inprogress会自动产生一次滚动，之后都是按照默认时间间隔(1H)来滚动。 </li>
<li>在HDFS中，会将每一次的写操作看作是一个事务，分配一个事务id，称之为txid。 </li>
<li>在HDFS中，将开始记录日志也看作是一个写操作也分配了一个事务id </li>
<li>任意一个edits文件的开头都是OP_START_LOG_SEGMENT，结尾都是OP_END_LOG_SEGMENT。这两步虽然当作写操作给分配了事务id，但是并没有产生元数据。 </li>
<li>上传文件，NameNode会将这个请求拆分 <ul>
<li>OP_ADD：生成同名文件.<em>COPYING</em> </li>
<li>OP_ALLOCATE_BLOCK_ID：分配BlockID </li>
<li>OP_SET_GENSTAMP_V2：分配时间戳编号 </li>
<li>OP_ADD_BLOCK：将Block的文件名对应 </li>
<li>OP_CLOSE：关流 </li>
<li>OP_RENAME_OLD：重命名 </li>
</ul>
</li>
<li>在HDFS中，文件一旦上传完毕就不能修改 </li>
<li>edits的转化命令：hdfs oev -i edits_xxx -o a.xml </li>
<li>fsimage的转化命令：hdfs oiv -i fsimage_xxx -o b.xml -p XML </li>
<li>每一个fsimage文件都会对应一个md5文件，这个md5文件是对fsimage文件来进行校验的 </li>
<li>VERSION文件中的重要属性 <ul>
<li>clusterID：用于进行校验的 </li>
<li>storageType：用于标记节点类型的 </li>
<li>blockpoolID：块池编号。主要是用于联邦HDFS中</li>
</ul>
</li>
</ol>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><h3 id="读-下载流程"><a href="#读-下载流程" class="headerlink" title="读/下载流程"></a>读/下载流程</h3><ol>
<li>客户端发起RPC请求到NameNode。 NameNode在收到请求之后，会检查要读取的文件是否存在；如果不存在，则直接报错；如果存在，则会给客户端来返回一个信号表示允许读取。 </li>
<li>客户端在收到信号之后，会再次给NameNode发送请求，请求获取第一个Block的存储位置。 </li>
<li>NameNode在收到请求之后，会查询元数据，然后将这个Block的存储位置(默认3个)放到一个队列中返回给客户端。 </li>
<li>客户端在收到队列之后，将地址从队列中全部取出，从这些地址中选取一个较近的节点来读取这个Block的数据同时读取对应的meta文件，读取完成之后会对这个Block进行checksum校验(实际上就是利用meta文件校验Block)，检查校验结果，如果校验失败则客户端会通知NameNode，客户端会从剩余的地址中重选选择一个重新读取。 </li>
<li>如果校验成功，则客户端会给NameNode发送请求，请求获取下一个Block的存储位置，重复3.4.5三个步骤。 直到读取完所有的Block，客户端会给NameNode发送结束信号。NameNode收到信号之后会关闭文件(关流)。</li>
</ol>
<h3 id="写-上传流程"><a href="#写-上传流程" class="headerlink" title="写/上传流程"></a>写/上传流程</h3><ol>
<li>客户端发起RPC请求到NameNode。 </li>
<li>NameNode在收到请求之后，会进行校验： <ul>
<li>校验是否有写入权限 </li>
<li>校验路径下是否有同名文件 </li>
</ul>
</li>
<li>如果校验失败则直接报错；如果校验成功，则NameNode会记录元数据，然后会给客户端返回一个信号表示允许上传。 </li>
<li>客户端收到信号之后，会再次发送请求到NameNode，请求获取第一个Block的存储位置。 </li>
<li>NameNode收到请求之后，会根据副本策略等待DataNode的心跳，然后给这个Block来分配DataNode，将DataNode的地址(默认3个)放到队列中返回给客户端<br>客户端收到队列之后，将地址从队列中取出，从这些地址中选择较近(拓扑距离)的节点将这个Block的第一个副本写入。当第一个副本写完之后，第一个副本所在的节点会通过管道(pipeline，本质上就是NIO中的Channel)将第二个副本写到对应的节点上，第二个副本写完之后，第二个副本所在的节点通过管道将第三个副本写入对应的节点上。第三个副本写完之后，第三个副本所在的节点会给第二个副本所在的节点返回一个ack信号表示写入成功；第二个副本收到ack之后会给第一个副本所在的节点返回一个ack信号；第一个副本所在的节点收到ack之后会再给客户端返回一个ack。 </li>
<li>客户端在收到ack之后表示当前Block的所有副本都已经写完，那么客户端就会给NameNode发送请求来获取下一个Block的地址，重复4.5.6三步。 </li>
<li>当所有的Block都写完之后，客户端就会给NameNode发送信号表示文件写完，NameNode在收到信号之后会关闭文件(实际上就是关流)。</li>
</ol>
<h3 id="删除流程"><a href="#删除流程" class="headerlink" title="删除流程"></a>删除流程</h3><ol>
<li>客户端发起RPC请求到NameNode </li>
<li>NameNode收到请求之后会将这个操作记录到edits中，记录完成之后会修改内存中的元数据，修改完成之后会给客户端返回一个ack信号表示删除成功。此时只是修改了元数据，真正的数据依然存储在DataNode上。 </li>
<li>NameNode会等待DataNode的心跳，收到心跳之后会校验存储信息，如果发现不一致，则会在心跳响应中要求删除对应的Block。 </li>
<li>DataNode在收到心跳响应之后，会删除对应的Block，此时数据才真正的从HDFS上移除。      </li>
</ol>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="link-muted mr-2" rel="tag" href="/tags/Hadoop/">Hadoop</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/25/BigData/Zookeeper/ZAB%E5%8D%8F%E8%AE%AE/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">ZAB协议</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/06/23/BigData/AVRO/"><span class="level-item">AVRO</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "vT8sFdsDv5VGpR7w7Wo0lyRb-gzGzoHsz",
            appKey: "MNAIdynlAB9EhdmY7lgJJyYo",
            
            avatar: "mm",
            
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            
            highlight: true,
            
            
            
            
            
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#概述"><span class="mr-2">1</span><span>概述</span></a></li><li><a class="is-flex" href="#技术细节"><span class="mr-2">2</span><span>技术细节</span></a><ul class="menu-list"><li><a class="is-flex" href="#基本概述"><span class="mr-2">2.1</span><span>基本概述</span></a></li><li><a class="is-flex" href="#Block-数据块"><span class="mr-2">2.2</span><span>Block 数据块</span></a></li><li><a class="is-flex" href="#NameNode-主节点"><span class="mr-2">2.3</span><span>NameNode 主节点</span></a></li><li><a class="is-flex" href="#副本放置策略"><span class="mr-2">2.4</span><span>副本放置策略</span></a></li><li><a class="is-flex" href="#机架感知策略"><span class="mr-2">2.5</span><span>机架感知策略</span></a></li><li><a class="is-flex" href="#SecondaryNameNode"><span class="mr-2">2.6</span><span>SecondaryNameNode</span></a></li><li><a class="is-flex" href="#DataNode"><span class="mr-2">2.7</span><span>DataNode</span></a></li><li><a class="is-flex" href="#基本命令"><span class="mr-2">2.8</span><span>基本命令</span></a></li><li><a class="is-flex" href="#回收站机制"><span class="mr-2">2.9</span><span>回收站机制</span></a></li></ul></li><li><a class="is-flex" href="#DFS目录"><span class="mr-2">3</span><span>DFS目录</span></a></li><li><a class="is-flex" href="#工作流程"><span class="mr-2">4</span><span>工作流程</span></a><ul class="menu-list"><li><a class="is-flex" href="#读-下载流程"><span class="mr-2">4.1</span><span>读/下载流程</span></a></li><li><a class="is-flex" href="#写-上传流程"><span class="mr-2">4.2</span><span>写/上传流程</span></a></li><li><a class="is-flex" href="#删除流程"><span class="mr-2">4.3</span><span>删除流程</span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Hadoop/"><span class="level-start"><span class="level-item">Hadoop</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/MapReduce/"><span class="level-start"><span class="level-item">MapReduce</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Zookeeper/"><span class="level-start"><span class="level-item">Zookeeper</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AVRO/"><span class="tag">AVRO</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hadoop/"><span class="tag">Hadoop</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MapReduce/"><span class="tag">MapReduce</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Zookeeper/"><span class="tag">Zookeeper</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="tag">大数据</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="tag">学习笔记</span><span class="tag is-grey-lightest">6</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Azurlin&#039;s blog" height="28"></a><p class="size-small"><span>&copy; 2021 Azurlin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>